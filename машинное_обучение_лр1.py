# -*- coding: utf-8 -*-
"""машинное обучение лр1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q8KgP_i-F8PEVYB1nV0_kF9_m2OQxntp

Импортирование нужных библиотек
"""

import tensorflow as tf
import numpy as np
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import mean_squared_error

"""Задаем входной и выходной вектора"""

x = np.arange(-1, 1, 0.1)
y = x*x

"""Разбиваем на обучающую и тестовую выборки"""

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)

"""Создаем, компилируем и обучаем модель

"""

model = tf.keras.Sequential([
  tf.keras.layers.Dense(10, activation='relu', input_shape=(1,)), # Первый слой
  tf.keras.layers.Dense(1) # Второй слой
])
optimizer = tf.keras.optimizers.Adam(0.1) # mse = 0.1
model.compile(loss='mean_squared_error', optimizer=optimizer)
history = model.fit(x_train, y_train, epochs=15, batch_size=32, validation_data=(x_test, y_test))

"""Проверка работоспособности модели и вывод предсказанных значений"""

classes = model.predict(x_test)
print(classes)

"""Построение графика изменения ошибки в процессе обучения"""

plt.plot(history.history['loss'], label='training')
plt.plot(history.history['val_loss'], label='validation')
plt.title('Model loss')
plt.ylabel('Loss') 
plt.xlabel('Epoch') 
plt.legend(loc="upper right")
plt.show()

"""На данном графике видно, как уменьшается ошибка на обучающем и валидационном наборах данных в зависимости от числа эпох обучения. Модель успешно обучается и хорошо обобщает полученные знания, потери стремятся к нулю.

Вычисляем ошибку
"""

# Получаем предсказания модели
y_pred = model.predict(x)

# Вычисляем MSE
mse = mean_squared_error(y, y_pred)

print("MSE: ", mse)

"""Архитектура нейронной сети"""

model.summary()

"""Используется нейронная сеть, состоящая из двух слоев: первый слой содержит 10 нейронов и использует функцию активации ReLU, а второй слой содержит 1 нейрон и не имеет функции активации. Таким образом, нейронная сеть имеет архитектуру (1, 10, 1), где первое число (1) обозначает размер входного вектора, а последнее число (1) - размер выходного вектора.

Создаем 2 модель с 3 слоями
"""

model_2 = tf.keras.Sequential([
  tf.keras.layers.Dense(20, activation='relu', input_shape=(1,)), # Первый слой
  tf.keras.layers.Dense(1),
  tf.keras.layers.Dense(1)
])
optimizer = tf.keras.optimizers.Adam(0.1) # mse = 0.1
model_2.compile(loss='mean_squared_error', optimizer=optimizer)
history_2 = model_2.fit(x_train, y_train, epochs=30, batch_size=32, validation_data=(x_test, y_test))

"""Проверка работоспособности модели и вывод предсказанных значений"""

classes = model_2.predict(x_test)
print(classes)

"""Построение графика изменения ошибки в процессе обучения"""

plt.plot(history_2.history['loss'], label='training')
plt.plot(history_2.history['val_loss'], label='validation')
plt.title('Model loss')
plt.ylabel('Loss') 
plt.xlabel('Epoch') 
plt.legend(loc="upper right")
plt.show()

"""На данном графике видно, как уменьшается ошибка на обучающем и валидационном наборах данных в зависимости от числа эпох обучения. Модель успешно обучается и хорошо обобщает полученные знания, потери стремятся к нулю.

Вычисляем ошибку
"""

# Получаем предсказания модели
y_pred = model_2.predict(x)

# Вычисляем MSE
mse = mean_squared_error(y, y_pred)

print("MSE: ", mse)

"""Архитектура нейронной сети"""

model_2.summary()

"""Нейронная сеть состоит из 3 слоев, первый слой содержит 20 нейронов и использует функцию активации ReLU, а второй и третий слоя содержат по 1 нейрону и не имеют функцию активации.

**Вывод:** Обе модели успешно обучаются и хорошо обобщают полученные знания. Среднеквадратическая ошибка показывает, что модель достаточно точно предсказывает выходные значения на заданных входных данных. Для данных, представленных в задании, лучше использовать 2 модель с 3 слоями и 20 нейронами. Она дает более точные результаты, чем 1 модель.
"""